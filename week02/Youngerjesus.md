# HTTP/2 를 위한 여정

## HTTP/1.1 의 이슈

- 다음 요청을 보내기 위해서는 이전 요청에 대한 응답을 전달 받아야 함. 이는 실제 서버 처리시간보다 대기 시간이 더 길어지는 문제가 생긴다.
  - (예시 기준으로는 80% 가 대기시간으로 사용. 여기서는 파이프라이닝은 고려 x. 파이프라이닝은 문제가 있음.)
- 요청의 헤더는 무조건 텍스트 기반이어야 한다. 본문은 바이너리를 쓸 수 있다고 하더라도. (컴퓨터에겐 최적이 아님.)
- 데이터를 효율적으로 인코딩 하지 않기 때문에 사이즈가 크다.
- 요청할 때 필요없는 헤더를 사용하기도 함. (for example, 이미지 파일을 요청하는데 쿠키를 사용함.)
- 보안을 위해서 매우 큰 HTTP 헤더를 사용함. (for example, Content-Security-Policy)

## HTTP/1.1 의 문제를 우회하는 방법

- 도메인 샤딩을 이용한 여러 HTTP 연결을 이용하는 방법
- 스프라이팅 (spriting) 과 캐싱과 같은 방법을 이용한 요청 자체를 줄이는 방법.

## HTTP/2 의 도입

- 야생에서 성공한 SPDY 를 기반으로 HTTP/2 를 도입 (바이너리 프로토콜로 64% 의 성능 개선, 이미지 처리에선 83% 의 성능 개선)
  - 단일 TCP 연결에서 모든 요청을 스트림 형태로 전송
  - 요청의 우선순위 지정 가능
  - 본문뿐 아니라 헤더를 압축하는 기능 제공
- 브라우저 기준으로 HTTP/1.1 은 여러 TCP 연결을 통해서 큐 처럼 동작하는 반면에 HTTP/2 는 단일 TCP 연결속에서 일괄적으로 보낸다. (대역폭을 고려해야함. 그래서 구현할 때 제한을 넣기도 한다. 아파치의 기준으로는 100 개 동시 요청 제한.)
- 엄청 큰 JS 파일과 같은 경우는 HTTP/2 가 크게 성능 향상에 일으키진 않는다. (전체 시간 = JS 다운 + JS 처리) (하나의 큰 파일 요청이라면 HTTP/1.1 과 HTTP/2 의 차이는 그렇게 큰 차이를 내지는 않을 수도 있다는 뜻.) (아니면 대역폭의 제한)
- 정리하면 HTTP/2 가 강한 경우는 다음과 같다.
  - HTTP 대기시간을 줄이는 경우 (수 많은 요청을 통해서) + 대역폭 이슈가 없을 때.
  - 헤더 압축도 있긴한대 크진 않을듯?

***

# HTTP/2 로 업그레이드

## Reverse Proxy 에서의 HTTP

- Reverse Proxy (like Nginx) 를 통과한 이후 부터는 HTTP/2 를 사용할 이유는 적어진다.
    - 브라우저가 아니라서 TCP 연결에 제약이 있는 것도 아님.
    - HTTP/2 가 해결하는 경우는 낮은 대역폭 + 높은 대기시간을 해결해준다.
    - Reverse Proxy 를 통과한 시점의 내부 네트워크에서는 높은 대역폭과 낮은 대기시간을 특징으로 가질 것.
    - Nginx 는 실제로 프록시를 통과한 연결에서는 HTTP/2 를 지원하지 않겠다고 말함.

## 브라우저의 경우 HTTP/2 와 HTTPS

- 브라우저는 HTTPS 를 사용하지 않는다면 HTTP/2 사용이 불가.

## CDN 에서는 HTTP/2 가 매우 효과적일듯.